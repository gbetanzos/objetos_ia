{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maestría en Inteligencia Artificial - HAIA: Clasificador de objetos\n",
    "### Profesor: Dr. Gaddiel Desirena López\n",
    "### Integrantes del equipo\n",
    "* Guillermo Betanzos\n",
    "* Luis Landeros\n",
    "* Sergio Rojas\n",
    "* Alberto Torres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "\n",
    "A lo largo del siguiente Jupyter notebook se detallará el propósito de cada pieza de código, con el cuál se define y construye un clasificador de objetos, en este caso el clasificador será diseñado para identificar cuatro clases de objeto: tazas, cubiertos, carritos de juguete y gorras.\n",
    "\n",
    "Cada sección de código incluye una sección de \"markup\" previa o posterior que explica lo que se intenta realizar en cada segmento.\n",
    "\n",
    "A continuación procederemos a importar librerías de carácter general que nos permitirá entre otras cosas graficar, realizar cálculos, acceder a funciones del sistema operativo y entre otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el directorio donde se encuentra el conjunto de imágenes que comprenderá nuestro conjunto de datos de entrada, dicho directorio se encuentra debajo del directorio ../data/train.\n",
    "      \n",
    "La función image_stats nos dará una idea de las dimensiones de las imágenes que se encuentran en dicho directorio, calcularemos promedios de ancho y alto de las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Height: 2854.3797468354433\n",
      "Max Height: 3648\n",
      "Min Height: 1280\n",
      "\n",
      "\n",
      "Average Width: 2674.025316455696\n",
      "Max Width: 4032\n",
      "Min Width: 960\n"
     ]
    }
   ],
   "source": [
    "DIR = '../data/train/'\n",
    "\n",
    "def image_stats():\n",
    "    heights = []\n",
    "    widths = []\n",
    "    img_count = 0\n",
    "    for img in os.listdir(DIR):\n",
    "        path = os.path.join(DIR, img)\n",
    "        if \"DS_Store\" not in path:\n",
    "            data = np.array(Image.open(path))\n",
    "            heights.append(data.shape[0])\n",
    "            widths.append(data.shape[1])\n",
    "            img_count += 1\n",
    "    avg_height = sum(heights) / len(heights)\n",
    "    avg_width = sum(widths) / len(widths)\n",
    "    print(\"Average Height: \" + str(avg_height))\n",
    "    print(\"Max Height: \" + str(max(heights)))\n",
    "    print(\"Min Height: \" + str(min(heights)))\n",
    "    print('\\n')\n",
    "    print(\"Average Width: \" + str(avg_width))\n",
    "    print(\"Max Width: \" + str(max(widths)))\n",
    "    print(\"Min Width: \" + str(min(widths)))\n",
    "\n",
    "image_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos una lista que contiene cada una de las clases de imágenes, esta lista tiene dos propósitos, por un lado identifica mediante una palabra la clase de objeto a identificar, por otro lado dentro del código se utilizará para asignar etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['taza','gorra','carrito','cubierto']\n",
    "#classes=['taza','carrito','cubierto']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez definida las clases de nuestro clasificador creamos una función que nos permitirá asignar a cada elemento del data set (conjunto de datos) dicha etiqueta, los archivos poseen el prefijo de las clases que definimos por lo que será relativamente sencillo generar una estructura que nos permita etiquetar apropiadamente cada elemento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-4-0c83f3e176d5>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-0c83f3e176d5>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    arr=np.append(arr,[1])\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def label_img(name,clases):\n",
    "    #print(\"----------------\")\n",
    "    arr=np.array([])\n",
    "    word_label = name.split('_')[0]\n",
    "    for l in classes:\n",
    "        #print(\"label:\",l,\" name:\",name)\n",
    "        if(word_label==l):\n",
    "            arr=np.append(arr,[1])\n",
    "            #print(\"label assigned:\",l)\n",
    "        else:\n",
    "            arr=np.append(arr,[0])\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante una función llamada <b>“load_training_data”</b> cargaremos el data set y al mismo tiempo etiquetaremos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 300\n",
    "\n",
    "def load_training_data(classes):\n",
    "    train_data = []\n",
    "    for img in os.listdir(DIR):\n",
    "        label = label_img(img,classes)\n",
    "        path = os.path.join(DIR, img)\n",
    "        if \"DS_Store\" not in path:\n",
    "            img = Image.open(path)\n",
    "            img = img.convert('L')\n",
    "            img = img.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n",
    "            train_data.append([np.array(img), label])\n",
    "            \n",
    "    shuffle(train_data)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_training_data(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**“train_data”** es la estructura en la que almacenamos los datos de entrenamiento, hacemos un muestreo de dicha estructura a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_data[0][0], cmap = 'gist_gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figura 1. Muestreo de objetos del conjunto de datos **train**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asimismo realizamos un muestreo de los datos que componen la estructura de etiquetas la cual tiene una correspondencia uno a uno con **“train_data”**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImages = np.array([i[0] for i in train_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "trainLabels = np.array([i[1] for i in train_data])\n",
    "print(trainLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librerías de **tensorflow/keras**, que nos permitirá realizar la construcción del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers. normalization import BatchNormalization\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo es multicapa, utilizamos principalmente varias capas de activación **ReLU**, adicionalmente empleamos redes neuronales convolucionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kGráfica ernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation = 'softmax'))\n",
    "#model.add(Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se despliega las diferentes capas de las que está compuesto el modelo así como el número de nodos que compone cada capa, la última capa utiliza activación **softmax** dado que lo que esperamos es una clasificación, esta última capa posee únicamente cuatro nodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabla 1. Despliegue de las diferentes capas que componen el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al momento de compilar el modelo estamos utilizando una función de pérdida catalogada como **“entropía cruzada” (crossentropy)** la cuál es una función de optimización que se utiliza en el caso de entrenar un modelo de clasificación, como el que estamos ejecutando ahora, realiza una clasificación de datos mediante la predicción de la probabilidad de que los datos pertenezcan a una clase o a otra. \n",
    "\n",
    "Dentro de Keras existen varios tipos de función de pérdida de entropía cruzada:\n",
    "<ul>\n",
    "<li>binary_crossentropy: Se utiliza como función de pérdida para el modelo de clasificación binaria. </li>\n",
    "<li>sparse_categorical_crossentropy: Se utiliza como una función de pérdida para el modelo de clasificación de clases múltiples donde a la etiqueta de salida se le asigna un valor entero (0, 1, 2, 3…). Esta función de pérdida es matemáticamente la misma que categorical_crossentropy. Simplemente tiene una interfaz diferente.</li>\n",
    "    <li><b>categorical_crossentropy:</b> Se utiliza como una función de pérdida para el modelo de clasificación de clases múltiples donde hay dos o más etiquetas de salida. A la etiqueta de salida se le asigna un valor de codificación de categoría única en forma de 0 y 1. La etiqueta de salida, si está presente en forma de número entero, se convierte en codificación categórica utilizando el método keras.utils to_categorical.</li>\n",
    "</ul>\n",
    "\n",
    "El optimizador utilizado para la compilación del modelo es **Adam** el cuál es un método de gradiente descendente estocástico que se basa en la estimación adaptativa de momentos de primer y segundo orden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lo que se refiere a los hiperparámetros utilizados, realizamos varios ejercicios con diferentes rangos de ellos, dados los resultados con los que experimentamos concluímos que los utilizados debajo fueron suficientes para alcanzar valores de pérdida/precisión aceptables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(trainImages, trainLabels, batch_size = 1, epochs = 30, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma forma que se realizó para el conjunto de datos de entrenamiento se realizará la carga de los datos de prueba con la función **load_test_data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = '../data/test/'\n",
    "def load_test_data(classes):\n",
    "    test_data = []\n",
    "    for img in os.listdir(TEST_DIR):\n",
    "        label = label_img(img,classes)\n",
    "        path = os.path.join(TEST_DIR, img)\n",
    "        if \"DS_Store\" not in path:\n",
    "            img = Image.open(path)\n",
    "            img = img.convert('L')\n",
    "            img = img.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n",
    "            test_data.append([np.array(img), label])\n",
    "    shuffle(test_data)\n",
    "    return test_data\n",
    "\n",
    "\n",
    "test_data = load_test_data(classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza el muestreo de datos, para verificar que efectivamente se están cargando adecuadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_data[4][0], cmap = 'gist_gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figura 2. Muestreo de objetos del conjunto de datos **test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza el código correspondiente para evaluar el data set con el modelo generado y se despliega la información pertinente a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImages = np.array([i[0] for i in test_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "testLabels = np.array([i[1] for i in test_data])\n",
    "\n",
    "loss, acc = model.evaluate(testImages, testLabels, verbose = 0)\n",
    "print(\"Accuracy:\",acc * 100, \" - Loss:\",loss)\n",
    "#print(model.predict(testImages))\n",
    "predict_arr=np.round(model.predict(testImages))\n",
    "print(predict_arr)\n",
    "print(\"El objeto es un(a):\",classes[np.where(predict_arr[4]==1.)[0][0]].upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que la gráfica se comporta en concordancia al número de objetos que el modelo pretende clasificar, realizamos ejercicios variando el número de clases de entrada y pudimos identificar que los valores trazados para pérdida varía con respecto a dicho número de clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "\n",
    "plt.title('Entrenamiento clasificador de objetos')\n",
    "plt.xlabel('Épocas')\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figura 3. Gráfica de los valores de precisión y pérdida para el modelo diseñado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "Deep Learning es una clase perteneciente a los algoritmos de \"machine learning\", el cual a través de múltiples capas extrae características de manera progresiva de mayor a menor nivel de características, partiendo de datos en crudo. \n",
    "\n",
    "Deep Learning es ampliamente utilizado en el procesamiento de imágenes, donde las capas más bajas van identificando bordes, mientras que las capas de mayor nivel identifican conceptos relvantes para los humanos, tales como dígitos, letras, rostros, etcétera.\n",
    "\n",
    "La clasificación de objetos vía redes neuronales depende en gran medida de un algoritmo en específico, redes neuronales convulosionales (convolutional neural networks, CNN), es a través de este tipo de redes en el procesamiento de imágenes, que se desenredan las abstracciones y seleccionan qué carácterísticas mejoran el rendimiento.\n",
    "\n",
    "Este reporte muestra un diseño de red en particular que logra alcanzar cifras aceptables en el discernimiento de las cuatro clases presentadas, los datos de pérdida y precisión del clasificador diseñado nos permiten concluir que el modelo es viable ya que superan el 80% de precisión, considerándolo un modelo que satisface los objetivos planteados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
