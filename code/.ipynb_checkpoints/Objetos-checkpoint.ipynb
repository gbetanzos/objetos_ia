{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maestría en Inteligencia Artificial - HAIA: Clasificador de objetos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lo largo del siguiente Jupyter notebook se detallará el propósito de cada pieza de código, el cuál nos permitirá definir un clasificador de objetos.\n",
    "\n",
    "A continuación procederemos a importar librerías de carácter general que nos permitirá entre otras cosas graficar, realizar cálculos, acceder a funciones del sistema operativo y entre otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el directorio donde se encuentra el conjunto de imágenes que comprenderá nuestro conjunto de datos de entrada, dicho directorio se encuentra debajo del directorio ../data/train.\n",
    "      \n",
    "La función image_stats nos dará una idea de las dimensiones de las imágenes que se encuentran en dicho directorio, calcularemos promedios de ancho y alto de las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '../data/train/'\n",
    "\n",
    "def image_stats():\n",
    "    heights = []\n",
    "    widths = []\n",
    "    img_count = 0\n",
    "    for img in os.listdir(DIR):\n",
    "        path = os.path.join(DIR, img)\n",
    "        if \"DS_Store\" not in path:\n",
    "            data = np.array(Image.open(path))\n",
    "            heights.append(data.shape[0])\n",
    "            widths.append(data.shape[1])\n",
    "            img_count += 1\n",
    "    avg_height = sum(heights) / len(heights)\n",
    "    avg_width = sum(widths) / len(widths)\n",
    "    print(\"Average Height: \" + str(avg_height))\n",
    "    print(\"Max Height: \" + str(max(heights)))\n",
    "    print(\"Min Height: \" + str(min(heights)))\n",
    "    print('\\n')\n",
    "    print(\"Average Width: \" + str(avg_width))\n",
    "    print(\"Max Width: \" + str(max(widths)))\n",
    "    print(\"Min Width: \" + str(min(widths)))\n",
    "\n",
    "image_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos una lista que contiene cada una de las clases de imágenes, esta lista tiene dos propósitos, por un lado identifica mediante una palabra la clase de objeto a identificar, por otro lado dentro del código se utilizará para asignar etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['taza','gorra','carrito','cubierto']\n",
    "#classes=['taza','carrito','cubierto']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez definida las clases de nuestro clasificador creamos una función que nos permitirá asignar a cada elemento del data set (conjunto de datos) dicha etiqueta, los archivos poseen el prefijo de las clases que definimos por lo que será relativamente sencillo generar una estructura que nos permita etiquetar apropiadamente cada elemento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(name,clases):\n",
    "    #print(\"----------------\")\n",
    "    arr=np.array([])\n",
    "    word_label = name.split('_')[0]\n",
    "    for l in classes:\n",
    "        #print(\"label:\",l,\" name:\",name)\n",
    "        if(word_label==l):\n",
    "            arr=np.append(arr,[1])\n",
    "            #print(\"label assigned:\",l)\n",
    "        else:\n",
    "            arr=np.append(arr,[0])\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante una función llamada <b>“load_training_data”</b> cargaremos el data set y al mismo tiempo etiquetaremos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 300\n",
    "\n",
    "def load_training_data(classes):\n",
    "    train_data = []\n",
    "    for img in os.listdir(DIR):\n",
    "        label = label_img(img,classes)\n",
    "        path = os.path.join(DIR, img)\n",
    "        if \"DS_Store\" not in path:\n",
    "            img = Image.open(path)\n",
    "            img = img.convert('L')\n",
    "            img = img.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n",
    "            train_data.append([np.array(img), label])\n",
    "            \n",
    "    shuffle(train_data)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_training_data(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**“train_data”** es la estructura en la que almacenamos los datos de entrenamiento, hacemos un muestreo de dicha estructura a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_data[0][0], cmap = 'gist_gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asimismo realizamos un muestreo de los datos que componen la estructura de etiquetas la cual tiene una correspondencia uno a uno con **“train_data”**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImages = np.array([i[0] for i in train_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "trainLabels = np.array([i[1] for i in train_data])\n",
    "print(trainLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librerías de **tensorflow/keras**, que nos permitirá realizar la construcción del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers. normalization import BatchNormalization\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo es multicapa, utilizamos principalmente varias capas de activación **ReLU**, adicionalmente empleamos redes neuronales convolucionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation = 'softmax'))\n",
    "#model.add(Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se despliega las diferentes capas de las que está compuesto el modelo así como el número de nodos que compone cada capa, la última capa utiliza activación **softmax** dado que lo que esperamos es una clasificación, esta última capa posee únicamente cuatro nodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al momento de compilar el modelo estamos utilizando una función de pérdida catalogada como **“entropía cruzada” (crossentropy)** la cuál es una función de optimización que se utiliza en el caso de entrenar un modelo de clasificación, como el que estamos ejecutando ahora, realiza una clasificación de datos mediante la predicción de la probabilidad de que los datos pertenezcan a una clase o a otra. \n",
    "\n",
    "Dentro de Keras existen varios tipos de función de pérdida de entropía cruzada:\n",
    "<ul>\n",
    "<li>binary_crossentropy: Se utiliza como función de pérdida para el modelo de clasificación binaria. </li>\n",
    "<li>sparse_categorical_crossentropy: Se utiliza como una función de pérdida para el modelo de clasificación de clases múltiples donde a la etiqueta de salida se le asigna un valor entero (0, 1, 2, 3…). Esta función de pérdida es matemáticamente la misma que categorical_crossentropy. Simplemente tiene una interfaz diferente.</li>\n",
    "    <li><b>categorical_crossentropy:</b> Se utiliza como una función de pérdida para el modelo de clasificación de clases múltiples donde hay dos o más etiquetas de salida. A la etiqueta de salida se le asigna un valor de codificación de categoría única en forma de 0 y 1. La etiqueta de salida, si está presente en forma de número entero, se convierte en codificación categórica utilizando el método keras.utils to_categorical.</li>\n",
    "</ul>\n",
    "\n",
    "El optimizador utilizado para la compilación del modelo es **Adam** el cuál es un método de gradiente descendente estocástico que se basa en la estimación adaptativa de momentos de primer y segundo orden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lo que se refiere a los hiperparámetros utilizados, realizamos varios ejercicios con diferentes rangos de ellos, dados los resultados con los que experimentamos concluímos que los utilizados debajo fueron suficientes para alcanzar valores de pérdida/precisión aceptables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(trainImages, trainLabels, batch_size = 1, epochs = 30, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma forma que se realizó para el conjunto de datos de entrenamiento se realizará la carga de los datos de prueba con la función **load_test_data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = '../data/test/'\n",
    "def load_test_data(classes):\n",
    "    test_data = []\n",
    "    for img in os.listdir(TEST_DIR):\n",
    "        label = label_img(img,classes)\n",
    "        path = os.path.join(TEST_DIR, img)\n",
    "        if \"DS_Store\" not in path:\n",
    "            img = Image.open(path)\n",
    "            img = img.convert('L')\n",
    "            img = img.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n",
    "            test_data.append([np.array(img), label])\n",
    "    shuffle(test_data)\n",
    "    return test_data\n",
    "\n",
    "\n",
    "test_data = load_test_data(classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza el muestreo de datos, para verificar que efectivamente se están cargando adecuadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_data[4][0], cmap = 'gist_gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza el código correspondiente para evaluar el data set con el modelo generado y se despliega la información pertinente a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImages = np.array([i[0] for i in test_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "testLabels = np.array([i[1] for i in test_data])\n",
    "\n",
    "loss, acc = model.evaluate(testImages, testLabels, verbose = 0)\n",
    "print(\"Accuracy:\",acc * 100, \" - Loss:\",loss)\n",
    "#print(model.predict(testImages))\n",
    "predict_arr=np.round(model.predict(testImages))\n",
    "print(predict_arr)\n",
    "print(\"El objeto es un(a):\",classes[np.where(predict_arr[4]==1.)[0][0]].upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "\n",
    "plt.title('Entrenamiento clasificador de objetos')\n",
    "plt.xlabel('Épocas')\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
